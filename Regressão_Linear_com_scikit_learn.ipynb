{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regressão Linear com scikit-learn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1FsaC50D8B2",
        "colab_type": "text"
      },
      "source": [
        "![Texto](https://dadosaocubo.com/wp-content/uploads/2020/06/DADOS-AO-CUBO-Vers%C3%A3o-04-1.png) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJElcCQ6DwXv",
        "colab_type": "text"
      },
      "source": [
        "[__D³__](https://dadosaocubo.com/) by [__Tiago Dias__](https://www.linkedin.com/in/diasctiago/) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0r9Hus5x5WiG",
        "colab_type": "text"
      },
      "source": [
        "Este é o primeiro post da trilha de modelos de Machine Learning (ML), vamos começar com os mais básicos e evoluir até chegar em modelos mais complexos. Mas que raios são esses tais modelos? Modelos de ML são algoritmos com funções matemáticas treinados para reconhecer determinados padrões e realizar predições a partir desses padrões. Mas não é esse monstro todo que parece, vamos por partes igual ao Jack.\n",
        "\n",
        "Neste post vamos abordar um dos modelos mais “básicos” de ML, mas não menos importante. A regressão linear apesar de um modelo relativamente simples, se comparado a outros que abordaremos nos próximos posts, tem um grande poder de predição e é solução para diversos problemas comuns. Antes de ver a sua aplicação com a biblioteca scikit-learn, vamos ver alguns conceitos importantes que não devem ser esquecidos.\n",
        "\n",
        "POST: [Regressão com scikit-learn](https://dadosaocubo.com/regressao-com-scikit-learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EBOh8Krz_Uq",
        "colab_type": "text"
      },
      "source": [
        "# Regressão linear"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCTwhFzE4xEh",
        "colab_type": "text"
      },
      "source": [
        "A regressão linear pode ser definida pela estatística como uma equação que busca estimar o(s) valor(es) de **y**, dados uma ou mais variáveis **x**. Sendo definido pela equação matemática:\n",
        "\n",
        "$$ y = a + bx $$\n",
        "\n",
        "Onde y é a variável dependente de x, a é o coeficiente linear e b é o coeficiente angular. Calma que não é tão difícil quanto parece, na prática é bem mais simples, vamos em frente.\n",
        "Curiosidades:\n",
        "*   Apesar do nome, a regressão linear também lida com relações não \n",
        "lineares.\n",
        "*   Em problemas de regressão, as variáveis independentes podem ser numéricas ou categóricas, enquanto a variável explicada (dependente) é sempre numérica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85aPlF1i0Ec3",
        "colab_type": "text"
      },
      "source": [
        "#### Teoria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlNjz28OCpxt",
        "colab_type": "text"
      },
      "source": [
        "Para ficar mais claro a nossa equação da regressão linear, podemos observar as variáveis **a** que vai definir o deslocamento da reta e a variável **b** que vai definir a inclinação da reta representada na figura abaixo.\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/dadosaocubo/regressao_linear/master/RegLinear.png\" width=\"350\"/>\n",
        "\n",
        "Nesta figura temos um exemplo onde a variável **y** é dependente de apenas uma variável **x**, mas nos problemas do mundo real, normalmente o que temos é a variável **y** dependente de várias variáveis **x**.\n",
        "\n",
        "$$ y = b_{0} + b_{1}x_{i1} + b_{2}x_{i2} + ... + + b_{p}x_{ip} $$\n",
        "\n",
        "Onde vamos ter o número p de variáveis **x**, onde **i** denota a **i**-ésima observação do conjunto de treino. Mas não vamos nos preocupar com o tamanho da conta que o algoritmo vai fazer, para nós o importante nesse momento é entender o conceito por trás da fórmula.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjZ-Sk450IdX",
        "colab_type": "text"
      },
      "source": [
        "#### Prática"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qqFLhshlI1p",
        "colab_type": "text"
      },
      "source": [
        "Aplicando todos esses conceitos e fórmulas que vimos acima, vamos utilizar o python e sua poderosa biblioteca para ML a [scikit-learn](https://scikit-learn.org/stable/index.html) lá podemos encontrar o famoso dataset com os preço de casas em Boston, disponível na prória biblioteca do scikit-learn como [load_boston()](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html). Mas o que é o scikit-learn? \n",
        "\n",
        "![scikit-learn](https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png)\n",
        "\n",
        "Essa biblioteca possui um conjunto de ferramentas para pré-processamento de dados e modelos de aprendizagem de máquina, inclusive a regressão linear, que se encontra no módulo **linear_model**, juntamente com outros modelos lineares. Mas vamos explorar todos os seus poderes especiais em diversos outros posts.\n",
        "\n",
        "Com os dados desse dataset é possível baseado nas suas features (variáveis independentes ou o **x**), fazer predições do target (variável dependente ou o **y**) neste problema o preço das casas em Boston.\n",
        "\n",
        "Dada essa introdução de alguns conceitos essenciais, vamos pegar os dados desse dataset, dividi-lo em duas partes, uma parte vamos utilizar para treinar o modelo (vamos mostrar ao modelo um conjunto de dados com as entradas e saídas conhecidas) e a outra parte que até então desconhecida pelo modelo, vamos usar para testar (vamos mostrar ao modelo um conjunto de dados com as entradas para que ele faça uma predição das saídas), esse seria um modelo supervisionado, quando temos dados rotulados, nossa saída já é conhecida e usamos ela para treinar o modelo, já o modelo semi-supervisionado e o não supervisionado abordaremos em outros posts para não perder o foco.\n",
        "\n",
        "Para começar vamos importar as bibliotecas necessárias para carga, tratamento e visualização dos dados, para criação do modelo e avaliação do mesmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVUvxn47pFJ1",
        "colab_type": "text"
      },
      "source": [
        "##### Importando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3P8w8f2pLQa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbhB3ugMW0jG",
        "colab_type": "text"
      },
      "source": [
        "Após carregar nossas bibliotecas, vamos carregar o nosso dataset para resolver nosso problema de regressão linear, nossos dados está dentro de uma das bibliotecas que foi carregada, o scikit-learn disponibiliza através do sklearn.datasets um conjunto de datasets para serem utilizados como exemplos e de lá selecionamos o **load_boston**, vamos ver agora como carregar ele."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaADaGRMpoEa",
        "colab_type": "text"
      },
      "source": [
        "##### Carregando dados do dataset de Boston"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oaCh3pRpnez",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "6d20423e-7c73-4524-8c37-9caa3a5c08fa"
      },
      "source": [
        "# Selecionando os dados do load_boston\n",
        "boston = load_boston()\n",
        "# Atribuindo as variáveis features, target, feature_names os seus valores correspondentes\n",
        "features, target, feature_names = boston.data, boston.target, boston.feature_names\n",
        "# Transformamos com o pandas esses dados em um DataFrame\n",
        "df = pd.DataFrame(data=features, columns=feature_names)\n",
        "# Juntamos ao DataFrame o target(y), nossa saida\n",
        "df['PRICE'] = target\n",
        "df.head(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00632</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2.31</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.538</td>\n",
              "      <td>6.575</td>\n",
              "      <td>65.2</td>\n",
              "      <td>4.0900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>296.0</td>\n",
              "      <td>15.3</td>\n",
              "      <td>396.9</td>\n",
              "      <td>4.98</td>\n",
              "      <td>24.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.02731</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.469</td>\n",
              "      <td>6.421</td>\n",
              "      <td>78.9</td>\n",
              "      <td>4.9671</td>\n",
              "      <td>2.0</td>\n",
              "      <td>242.0</td>\n",
              "      <td>17.8</td>\n",
              "      <td>396.9</td>\n",
              "      <td>9.14</td>\n",
              "      <td>21.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      CRIM    ZN  INDUS  CHAS    NOX  ...    TAX  PTRATIO      B  LSTAT  PRICE\n",
              "0  0.00632  18.0   2.31   0.0  0.538  ...  296.0     15.3  396.9   4.98   24.0\n",
              "1  0.02731   0.0   7.07   0.0  0.469  ...  242.0     17.8  396.9   9.14   21.6\n",
              "\n",
              "[2 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKX_Ik6jp69i",
        "colab_type": "text"
      },
      "source": [
        "##### Visualizando dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsFWl-zlYUXe",
        "colab_type": "text"
      },
      "source": [
        "Vamos ter alguns posts específicos só para ensinar e dar dicas sobre a exploração de dados, uma parte fundamental para a criação do modelo, sem conhecer os dados fica complicado criar um modelo eficiente para o problema.\n",
        "Mas vamos ver aqui duas funções clássicas do pandas(biblioteca open source utilizada para visualização e manipulação de dados):\n",
        "\n",
        "*   **describe()** - lista as variáveis e mostra alguns dados estatísticos básicos como (mínimo, máximo, média, e outros) não deixe de conferir o post sobre estatística para saber mais sobre esses dados ([Estatística Descritiva Univariada](https://dadosaocubo.com/estatistica-descritiva-univariada/)).\n",
        "*   **info()** - lista informações sobre as colunas, utilizei para sabe se todas as features (x), nossas entradas eram numéricas e se não tinham dados nulos, pré requisitos para os modelos de regressão linear.\n",
        "\n",
        "Após analisar estas funções podemos ir para nosso modelo de regressão linear. Só lembrando que estamos tratando do conceito da regressão linear, então pode parecer está faltando algumas etapas (como é um dataset de exemplo podemos pular algumas etapas para fins de demonstração, pois os dados já foram tratados) ná dúvida sobre as etapas dos projetos de ciência de dados pode conferir neste post ([Pipeline dos Projetos de Ciência de Dados](https://dadosaocubo.com/pipeline-dos-projetos-de-ciencia-de-dados/)).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efGV6R4Jp9Ux",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "fb0054f8-64a7-4199-bda0-b3bf81b348b5"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "      <th>PRICE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "      <td>506.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>3.613524</td>\n",
              "      <td>11.363636</td>\n",
              "      <td>11.136779</td>\n",
              "      <td>0.069170</td>\n",
              "      <td>0.554695</td>\n",
              "      <td>6.284634</td>\n",
              "      <td>68.574901</td>\n",
              "      <td>3.795043</td>\n",
              "      <td>9.549407</td>\n",
              "      <td>408.237154</td>\n",
              "      <td>18.455534</td>\n",
              "      <td>356.674032</td>\n",
              "      <td>12.653063</td>\n",
              "      <td>22.532806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>8.601545</td>\n",
              "      <td>23.322453</td>\n",
              "      <td>6.860353</td>\n",
              "      <td>0.253994</td>\n",
              "      <td>0.115878</td>\n",
              "      <td>0.702617</td>\n",
              "      <td>28.148861</td>\n",
              "      <td>2.105710</td>\n",
              "      <td>8.707259</td>\n",
              "      <td>168.537116</td>\n",
              "      <td>2.164946</td>\n",
              "      <td>91.294864</td>\n",
              "      <td>7.141062</td>\n",
              "      <td>9.197104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.006320</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.460000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.385000</td>\n",
              "      <td>3.561000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>1.129600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>187.000000</td>\n",
              "      <td>12.600000</td>\n",
              "      <td>0.320000</td>\n",
              "      <td>1.730000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.082045</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.190000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.449000</td>\n",
              "      <td>5.885500</td>\n",
              "      <td>45.025000</td>\n",
              "      <td>2.100175</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>279.000000</td>\n",
              "      <td>17.400000</td>\n",
              "      <td>375.377500</td>\n",
              "      <td>6.950000</td>\n",
              "      <td>17.025000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.256510</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>9.690000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.538000</td>\n",
              "      <td>6.208500</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>3.207450</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>330.000000</td>\n",
              "      <td>19.050000</td>\n",
              "      <td>391.440000</td>\n",
              "      <td>11.360000</td>\n",
              "      <td>21.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>3.677083</td>\n",
              "      <td>12.500000</td>\n",
              "      <td>18.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.624000</td>\n",
              "      <td>6.623500</td>\n",
              "      <td>94.075000</td>\n",
              "      <td>5.188425</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>666.000000</td>\n",
              "      <td>20.200000</td>\n",
              "      <td>396.225000</td>\n",
              "      <td>16.955000</td>\n",
              "      <td>25.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>88.976200</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>27.740000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.871000</td>\n",
              "      <td>8.780000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>12.126500</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>711.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>396.900000</td>\n",
              "      <td>37.970000</td>\n",
              "      <td>50.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             CRIM          ZN       INDUS  ...           B       LSTAT       PRICE\n",
              "count  506.000000  506.000000  506.000000  ...  506.000000  506.000000  506.000000\n",
              "mean     3.613524   11.363636   11.136779  ...  356.674032   12.653063   22.532806\n",
              "std      8.601545   23.322453    6.860353  ...   91.294864    7.141062    9.197104\n",
              "min      0.006320    0.000000    0.460000  ...    0.320000    1.730000    5.000000\n",
              "25%      0.082045    0.000000    5.190000  ...  375.377500    6.950000   17.025000\n",
              "50%      0.256510    0.000000    9.690000  ...  391.440000   11.360000   21.200000\n",
              "75%      3.677083   12.500000   18.100000  ...  396.225000   16.955000   25.000000\n",
              "max     88.976200  100.000000   27.740000  ...  396.900000   37.970000   50.000000\n",
              "\n",
              "[8 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCbCmFJVp88V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "outputId": "38f17962-94fc-410d-c476-6c2ba0f89037"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 506 entries, 0 to 505\n",
            "Data columns (total 14 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   CRIM     506 non-null    float64\n",
            " 1   ZN       506 non-null    float64\n",
            " 2   INDUS    506 non-null    float64\n",
            " 3   CHAS     506 non-null    float64\n",
            " 4   NOX      506 non-null    float64\n",
            " 5   RM       506 non-null    float64\n",
            " 6   AGE      506 non-null    float64\n",
            " 7   DIS      506 non-null    float64\n",
            " 8   RAD      506 non-null    float64\n",
            " 9   TAX      506 non-null    float64\n",
            " 10  PTRATIO  506 non-null    float64\n",
            " 11  B        506 non-null    float64\n",
            " 12  LSTAT    506 non-null    float64\n",
            " 13  PRICE    506 non-null    float64\n",
            "dtypes: float64(14)\n",
            "memory usage: 55.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LFakLow0QTJ",
        "colab_type": "text"
      },
      "source": [
        "##### LinearRegression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AniEVSBjcKh0",
        "colab_type": "text"
      },
      "source": [
        "Vamos começar selecionando nossas features e target, entradas e saidas ou simplismente X e y são nomes comuns que podem aparecer na literatura. Para ficar mais didático vamos selecionar apenas uma variável de entrada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjtrNGfDtrK6",
        "colab_type": "text"
      },
      "source": [
        "Selecionando Variáveis para o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLjlj0O-tsa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df[['LSTAT']]\n",
        "y = df.PRICE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2U9g4njckgs",
        "colab_type": "text"
      },
      "source": [
        "Após a seleção do X e y, como falado anteriormente, vamos dividir nossos dados em treino e teste para que possamos após a criação do modelo testar a performance do mesmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d90cFCHPtyKY",
        "colab_type": "text"
      },
      "source": [
        "Dividindo os dados em treino e teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuGE5uw5c41U",
        "colab_type": "text"
      },
      "source": [
        "A variável **test_size** vai definir o tamanho dos nossos dados selecionados para teste, o tamanho dessa divisão, não existe uma regra para isso, vai depender de cada problema e principalmente do tamanho do conjunto de dados que temos para treino."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZI4bNd9t1Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TykiMmyadoCe",
        "colab_type": "text"
      },
      "source": [
        "Com nossos dados de treino dividido, podemos criar o modelo, que é uma tarefa relativamente simples, na prática o mais dificil é saber: Qual melhor modelo usar? Quais são os melhores hiperparâmetros? Mas essas e outras dúvidas vamos responder em outros posts."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEExrZC_t2IM",
        "colab_type": "text"
      },
      "source": [
        "Criando o modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR_o1VVRootD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "996c9237-38f9-46e7-8577-55b3bd456f89"
      },
      "source": [
        "# Criando o modelo LinearRegression\n",
        "regr = LinearRegression()\n",
        "# Realizar treinamento do modelo\n",
        "regr.fit(X_train, y_train)\n",
        "# Realizar predição com os dados separados para teste\n",
        "y_pred = regr.predict(X_test)\n",
        "# Visualização dos 20 primeiros resultados\n",
        "y_pred[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([17.18471224, 31.49770516,  6.61946352, 32.75950848, 22.24134198,\n",
              "       16.38431461, 20.82887557, 29.39783843, 23.55964396, 29.87807701,\n",
              "       29.99107433,  6.98670479, 29.21892602, 17.87211256, 20.63113027,\n",
              "       18.45593201, 26.84598246, 30.24531828, 21.29028126,  9.48206211])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ7G0dvbhJz6",
        "colab_type": "text"
      },
      "source": [
        "Lembra quando nós definimos a função da regressão linear? \n",
        "$$ y = a + bx $$ \n",
        "Abaixo nós temos o resultado de **a** o coeficiente linear e **b** o coéficiente angular do nosso modelo gerado, dados esses valores conseguimos prever qualquer ponto da reta somente com o valor de **x**, então temos o nosso modelo de regressão linear.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn8Zz_MCooqc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fb43bbf9-fe39-4834-b5f4-b91b85485de8"
      },
      "source": [
        "print('Coeficiente Angular:', regr.coef_)\n",
        "print('Coeficiente Linear:', regr.intercept_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coeficiente Angular: [-0.94164427]\n",
            "Coeficiente Linear: 34.56746548140728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6MNA9KjiDmL",
        "colab_type": "text"
      },
      "source": [
        "E agora? Terminanos? Nosso modelo ficou bom? Ainda precisamos avaliar nosso modelo afim de saber se ele resolve nosso problema com um erro aceitável. Erro? Não pode ter erro. Calma, os modelos são calculos baseados em estatisticas então sempre vamos ter um erro, o que podemos fazer é minimizar esse erro, para que ele seja aceitável para o nosso problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mN1ll9420i0D",
        "colab_type": "text"
      },
      "source": [
        "#### Validação de regressão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8k0K1AljUgd",
        "colab_type": "text"
      },
      "source": [
        "Vejamos o gráfico abaixo, em azul nossa linha de regressão linear, em laranja nossas saidas originais, nosso erro é dado por **e** que é a diferença entre a saida original e a saida prevista pelo modelo, essa diferença pode ser positiva ou negativa e isso vai influenciar tambem na nossa analise de erro, vamos analisar o **erro médio absoluto**, o **erro quadrático médio** e o **coeficiente de determinação**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSoUlCkK3REJ",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/dadosaocubo/regressao_linear/master/RegLinearErro.png\" width=\"350\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Hld2D-D0yBu",
        "colab_type": "text"
      },
      "source": [
        "##### Erro Médio Absoluto (Median Absolute Error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fq3gcYFClKFt",
        "colab_type": "text"
      },
      "source": [
        "O erro médio absoluto (MAE) é a média da soma de todos os **e** do nosso gráfico de erros, as sua análise sofre uma interferencia devido aos erros positivos e negativos se anularem.\n",
        "\n",
        "Para calcular o MAE do nosso modelo podemos usar o código abaixo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgwcL0CTqiqU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "096a5bbd-d5df-4ce6-f3b4-f1ddad09e6a6"
      },
      "source": [
        "print('MAE: %.2f' % mean_absolute_error(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 4.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UNEz9yN04Dd",
        "colab_type": "text"
      },
      "source": [
        "##### Erro Quadrado Médio (Mean Squared Error)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCUR9pJ1mSZR",
        "colab_type": "text"
      },
      "source": [
        "O erro quadrado médio (MSE) é a média da soma de todos os **e** elevados ao quadrado do nosso gráfico, o fato de ele ter as diferencas elevadas ao quadrados resolve o problema de os erros positivos e negativos se anularem, sendo mais preciso que o MAE.\n",
        "\n",
        "Para calcular o MSE do nosso modelo podemos usar o código abaixo.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrmfIapBq1Lo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35380310-05ad-4ee0-a28c-68d92408533f"
      },
      "source": [
        "print('MSE: %.2f' % mean_squared_error(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: 34.68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoZaLQ34q6R7",
        "colab_type": "text"
      },
      "source": [
        "##### Coeficiente de Determinação (R2 Score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkEX49gunOtm",
        "colab_type": "text"
      },
      "source": [
        "O coeficiente de Determinação (R²) varia entre 0 e 1 e expressa a quantidade da variância dos dados que é explicada pelo modelo linear. Explicando a variância da variável dependente a partir da variável independente.\n",
        "\n",
        "No nosso exemplo o R² = 0,59 significa que o modelo linear explica 59% da variância da variável dependente a partir da variável independente."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5hKfNhprAja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "782e7599-8a98-4ea0-84bd-5896a0997ae5"
      },
      "source": [
        "print('R2 Score: %.2f' % r2_score(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 Score: 0.54\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvtNVYS2orxl",
        "colab_type": "text"
      },
      "source": [
        "Dada as explicações para avaliação do modelo, vamos visualizar os dados reais de forma gráfica para fixar os conhecimentos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wTz7pddrFgi",
        "colab_type": "text"
      },
      "source": [
        "##### Visualizando os resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KoD0KVWo4TT",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Podemos no gráfico abaixo, os pontos pretos que representam os nossos dados reais e em azul a reta de regressão linear do nosso modelo, dá para observar que temos dados um tanto dispersos, o que não faz o nosso modelos performar tão bem. Ao longo dos próximos posts vão entender melhor como melhorar nossos modelos, tratar os dados dispersos, incluir novas variáveis de entrada entre outras técnicas que podem ser aplicadas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kE9TZwgrKXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "1583031a-15ab-4401-e89f-cf880131b93b"
      },
      "source": [
        "plt.rcParams['figure.figsize'] = (11,7)\n",
        "plt.scatter(X_test, y_test,  color='black')\n",
        "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBxwvZgt_Il9",
        "colab_type": "text"
      },
      "source": [
        "### Referências\n",
        "*   [Introduction to Machine Learning Algorithms: Linear Regression](https://towardsdatascience.com/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a)\n",
        "*   [Regressão linear](https://pt.wikipedia.org/wiki/Regress%C3%A3o_linear)\n",
        "*   [Understanding Regression Error Metrics in Python](https://www.dataquest.io/blog/understanding-regression-error-metrics/)"
      ]
    }
  ]
}